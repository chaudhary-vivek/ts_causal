{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torch_scatter/_scatter_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch8autograd13_wrap_outputsERKNSt3__16vectorIN2at6TensorENS1_9allocatorIS4_EEEERKNS1_13unordered_setIPN3c1010TensorImplENS1_4hashISD_EENS1_8equal_toISD_EENS5_ISD_EEEESL_NSB_8ArrayRefINSB_8optionalIS4_EEEERKNS1_10shared_ptrINS0_4NodeEEENS1_8functionIFS7_S7_S7_EEE'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torch_sparse/_diag_cpu.so, 0x0006): symbol not found in flat namespace '__ZN3c106detail19maybe_wrap_dim_slowExxb'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlying SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "# 0: x_1 [], \n",
    "# 1: x_2 [((0, 0), coeff, lin_f), ((5, 0), coeff, lin_f)], \n",
    "# 2: M   [((1, 0), coeff, lin_f), ((5, 0), coeff, lin_f)],\n",
    "# 3: Y   [((1, 0), coeff, lin_f), ((2, 0), coeff, lin_f), ((6, 0), coeff, lin_f), ((7, 0), coeff, lin_f)],\n",
    "# 4: Z_1 [((5, 0), coeff, lin_f), ((7, 0), coeff, lin_f)], \n",
    "# 5: Z_2 [], \n",
    "# 6: Z_3 [],\n",
    "# 7: [],\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248834</td>\n",
       "      <td>-0.087867</td>\n",
       "      <td>-1.288305</td>\n",
       "      <td>-1.123094</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929797</td>\n",
       "      <td>-0.160463</td>\n",
       "      <td>1.274541</td>\n",
       "      <td>0.237258</td>\n",
       "      <td>-0.501115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.187943</td>\n",
       "      <td>0.356178</td>\n",
       "      <td>-0.912174</td>\n",
       "      <td>-1.018844</td>\n",
       "      <td>0.055279</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0   x1        x2        x3        x4        x5        x6  x7\n",
       "0  0.0  0.0  0.248834 -0.087867 -1.288305 -1.123094  0.973667 NaN\n",
       "1  0.0  0.0  0.929797 -0.160463  1.274541  0.237258 -0.501115 NaN\n",
       "2  0.0  0.0 -1.187943  0.356178 -0.912174 -1.018844  0.055279 NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('intervention_data2.pkl')\n",
    "# df = pd.read_pickle('lin_df.pkl')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1: x shape = torch.Size([8, 5])\n",
      "Graph 2: x shape = torch.Size([8, 5])\n",
      "Graph 3: x shape = torch.Size([8, 5])\n",
      "Graph 4: x shape = torch.Size([8, 5])\n",
      "Graph 5: x shape = torch.Size([8, 5])\n",
      "KeyError at timestep 9999: 10000\n",
      "Skipping this timestep.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (8x5 and 8x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graph \u001b[38;5;129;01min\u001b[39;00m train_graphs:\n\u001b[1;32m    110\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 111\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(graph)\n\u001b[1;32m    112\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, graph\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m    113\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mTimeSeriesGNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m      9\u001b[0m     x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:260\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m--> 260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x5 and 8x64)"
     ]
    }
   ],
   "source": [
    "\n",
    "class TimeSeriesGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TimeSeriesGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Only predict for x0\n",
    "        x0_pred = self.linear(x[0].unsqueeze(0))\n",
    "        \n",
    "        return x0_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lin_f(x):\n",
    "    return x\n",
    "\n",
    "coeff = 0.5\n",
    "links_coeffs = {\n",
    "    0: [], \n",
    "    1: [((0, 0), coeff, lin_f), ((5, 0), coeff, lin_f)], \n",
    "    2: [((1, 0), coeff, lin_f), ((5, 0), coeff, lin_f)],\n",
    "    3: [((1, 0), coeff, lin_f), ((2, 0), coeff, lin_f), ((6, 0), coeff, lin_f), ((7, 0), coeff, lin_f)],\n",
    "    4: [((5, 0), coeff, lin_f), ((7, 0), coeff, lin_f)], \n",
    "    5: [],\n",
    "    6: [],\n",
    "    7: [],\n",
    "}\n",
    "\n",
    "def prepare_data(df, num_timesteps=None, max_lag=1):\n",
    "    if num_timesteps is None or num_timesteps > len(df):\n",
    "        num_timesteps = len(df)\n",
    "\n",
    "    graphs = []\n",
    "    for t in range(max_lag, num_timesteps):\n",
    "        try:\n",
    "            # Create a list to hold features for each variable\n",
    "            features = []\n",
    "            \n",
    "            # Prepare features for each variable\n",
    "            for var in range(8):  # 8 variables in total\n",
    "                var_features = [df.loc[t, f'x{var}']]  # Current value\n",
    "                for link in links_coeffs[var]:\n",
    "                    source_var, lag = link[0]\n",
    "                    if t - lag >= 0:\n",
    "                        var_features.append(df.loc[t - lag, f'x{source_var}'])\n",
    "                features.append(var_features)\n",
    "            \n",
    "            # Convert to tensor, padding shorter sequences with zeros\n",
    "            max_features = max(len(f) for f in features)\n",
    "            x = torch.tensor([f + [0] * (max_features - len(f)) for f in features], dtype=torch.float)\n",
    "            \n",
    "            # Create edge_index based on links_coeffs\n",
    "            edge_index = []\n",
    "            for target, sources in links_coeffs.items():\n",
    "                for source, _, _ in sources:\n",
    "                    edge_index.append([source[0], target])\n",
    "            \n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            \n",
    "            # Use all variables as targets for simplicity\n",
    "            y = torch.tensor([df.loc[t+1, f'x3']], dtype=torch.float)\n",
    "            \n",
    "            graphs.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "            \n",
    "            # Debugging: print the shape of x for the first few graphs\n",
    "            if len(graphs) <= 5:\n",
    "                print(f\"Graph {len(graphs)}: x shape = {x.shape}\")\n",
    "            \n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError at timestep {t}: {e}\")\n",
    "            print(\"Skipping this timestep.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error at timestep {t}: {e}\")\n",
    "            print(\"DataFrame at this timestep:\")\n",
    "            print(df.loc[t-max_lag:t+1])\n",
    "            raise\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "\n",
    "\n",
    "graphs = prepare_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_graphs = graphs[:-100]\n",
    "test_graphs = graphs[-100:]\n",
    "\n",
    "# Initialize the model\n",
    "model = TimeSeriesGNN(input_dim=5, hidden_dim=64, output_dim=1)\n",
    "\n",
    "# Training loop (simplified)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    losses_ = []\n",
    "    for graph in train_graphs:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph)\n",
    "        loss = criterion(out, graph.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses_.append(loss.detach())\n",
    "    print(f'epoch {epoch} __ loss {np.mean(losses_)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for graph in test_graphs:\n",
    "        pred = model(graph)\n",
    "        predictions.append(pred.item())\n",
    "        true_values.append(graph.y.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_smape(true_values, predictions):\n",
    "    \"\"\"\n",
    "    Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    \n",
    "    :param true_values: List or array of actual values\n",
    "    :param predictions: List or array of predicted values\n",
    "    :return: SMAPE value\n",
    "    \"\"\"\n",
    "    true_values = np.array(true_values)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denominator = np.abs(true_values) + np.abs(predictions)\n",
    "    \n",
    "    # If both true and predicted are zero, consider it as a perfect prediction\n",
    "    zero_indices = denominator == 0\n",
    "    denominator[zero_indices] = 1  # Temporarily set to 1 to avoid division by zero\n",
    "    \n",
    "    smape = np.mean(2 * np.abs(predictions - true_values) / denominator)\n",
    "    \n",
    "    # Adjust for cases where both true and predicted were zero\n",
    "    smape = smape * (1 - zero_indices.mean())\n",
    "    \n",
    "    return smape * 100  # Convert to percentage\n",
    "\n",
    "# Usage:\n",
    "smape = calculate_smape(true_values, predictions)\n",
    "print(f\"SMAPE: {smape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_true_vs_predicted(true_values, predictions):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(true_values, label='True Values', color='blue')\n",
    "    plt.plot(predictions, label='Predictions', color='red')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('True Values vs Predictions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_true_vs_predicted(true_values, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
